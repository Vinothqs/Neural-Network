{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1dca7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "sql_folder = './sql'  # Folder containing your .sql files\n",
    "output_folder = './csv'  # Folder to save extracted CSVs\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3774975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rows_from_sql(sql_text):\n",
    "    insert_statements = re.findall(\n",
    "        r\"INSERT INTO [`\\\"]?([\\w_]+)[`\\\"]?.*?VALUES\\s*(.*?);\", \n",
    "        sql_text, re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    extracted_data = {}\n",
    "    for table_name, values_block in insert_statements:\n",
    "        rows = re.findall(r\"\\((.*?)\\)\", values_block, re.DOTALL)\n",
    "        parsed_rows = []\n",
    "        for row in rows:\n",
    "            # Split by comma but ignore commas inside quotes\n",
    "            values = re.split(r\",(?=(?:[^']*'[^']*')*[^']*$)\", row)\n",
    "            cleaned = [v.strip().strip(\"'\").strip('\"') for v in values]\n",
    "            parsed_rows.append(cleaned)\n",
    "        if table_name in extracted_data:\n",
    "            extracted_data[table_name].extend(parsed_rows)\n",
    "        else:\n",
    "            extracted_data[table_name] = parsed_rows\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a691f1c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️ No valid data found in 01_mysql_create.sql\n",
      "✅ Extracted 9235 rows from 02_mysql_populate_author.sql → author.csv\n",
      "✅ Extracted 568 rows from 03_mysql_populate_publisher.sql → publisher.csv\n",
      "✅ Extracted 27 rows from 04_mysql_populate_lookups.sql → book_language.csv\n",
      "✅ Extracted 4 rows from 04_mysql_populate_lookups.sql → shipping_method.csv\n",
      "✅ Extracted 2 rows from 04_mysql_populate_lookups.sql → address_status.csv\n",
      "✅ Extracted 6 rows from 04_mysql_populate_lookups.sql → order_status.csv\n",
      "✅ Extracted 37 rows from 05_mysql_populate_book.sql → book.csv\n",
      "✅ Extracted 17642 rows from 06_mysql_populate_bookauthor.sql → book_author.csv\n",
      "✅ Extracted 232 rows from 07_mysql_populate_country.sql → country.csv\n",
      "✅ Extracted 1000 rows from 08_mysql_populate_address.sql → address.csv\n",
      "✅ Extracted 2000 rows from 09_mysql_populate_customer.sql → customer.csv\n",
      "⚠️ No valid data found in 10_mysql_populate_others.sql\n",
      "⚠️ No valid data found in 11_mysql_populate_order.sql\n",
      "⚠️ No valid data found in 12_mysql_populate_orderline.sql\n",
      "⚠️ No valid data found in 13_mysql_populate_orderhistory.sql\n"
     ]
    }
   ],
   "source": [
    "for filename in sorted(os.listdir(sql_folder)):\n",
    "    if filename.endswith(\".sql\"):\n",
    "        path = os.path.join(sql_folder, filename)\n",
    "        with open(path, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "        tables = extract_rows_from_sql(content)\n",
    "        if not tables:\n",
    "            print(f\"⚠️ No valid data found in {filename}\")\n",
    "        for table, rows in tables.items():\n",
    "            df = pd.DataFrame(rows)\n",
    "            csv_path = os.path.join(output_folder, f\"{table}.csv\")\n",
    "            df.to_csv(csv_path, index=False, header=False)\n",
    "            print(f\"✅ Extracted {len(rows)} rows from {filename} → {table}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e07f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "sql_folder = './sql'\n",
    "output_folder = './csv_output'\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1251622",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_rows_from_sql(sql_text):\n",
    "    insert_statements = re.findall(\n",
    "        r'INSERT INTO [`\"]?([\\w_]+)[`\"]?.*?VALUES\\s*(.*?);',\n",
    "        sql_text, re.DOTALL | re.IGNORECASE\n",
    "    )\n",
    "    extracted_data = {}\n",
    "    for table_name, values_block in insert_statements:\n",
    "        rows = re.findall(r\"\\((.*?)\\)\", values_block, re.DOTALL)\n",
    "        parsed_rows = []\n",
    "        for row in rows:\n",
    "            values = re.split(r\",(?=(?:[^']*'[^']*')*[^']*$)\", row)\n",
    "            cleaned = [v.strip().strip(\"'\").strip('\"') for v in values]\n",
    "            parsed_rows.append(cleaned)\n",
    "        if table_name in extracted_data:\n",
    "            extracted_data[table_name].extend(parsed_rows)\n",
    "        else:\n",
    "            extracted_data[table_name] = parsed_rows\n",
    "    return extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ad6550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ customer_address.csv created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_customer_address():\n",
    "    customer_ids = list(range(1, 2001))\n",
    "    address_ids = random.choices(range(1, 1001), k=2000)\n",
    "    status_ids = [1] * 2000\n",
    "\n",
    "    customer_ids += random.choices(range(1, 2001), k=750)\n",
    "    address_ids += random.choices(range(1, 1001), k=750)\n",
    "    status_ids += [1] * 750\n",
    "\n",
    "    customer_ids += random.choices(range(1, 2001), k=400)\n",
    "    address_ids += random.choices(range(1, 1001), k=400)\n",
    "    status_ids += [2] * 400\n",
    "\n",
    "    customer_ids += random.choices(range(1, 2001), k=200)\n",
    "    address_ids += random.choices(range(1, 1001), k=200)\n",
    "    status_ids += [1] * 200\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'customer_id': customer_ids,\n",
    "        'address_id': address_ids,\n",
    "        'status_id': status_ids\n",
    "    })\n",
    "    df.to_csv(f\"{output_folder}/customer_address.csv\", index=False)\n",
    "    print(\"✅ customer_address.csv created\")\n",
    "generate_customer_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82d9c859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ cust_order.csv created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_cust_order():\n",
    "    num_orders = 7550\n",
    "    data = {\n",
    "        \"order_date\": [datetime.now() - timedelta(days=random.randint(0, 1095)) for _ in range(num_orders)],\n",
    "        \"customer_id\": [random.randint(1, 2000) for _ in range(num_orders)],\n",
    "        \"shipping_method_id\": [random.randint(1, 4) for _ in range(num_orders)],\n",
    "        \"dest_address_id\": [random.randint(1, 1000) for _ in range(num_orders)],\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"order_date\"] = df[\"order_date\"].dt.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    df.to_csv(f\"{output_folder}/cust_order.csv\", index=False)\n",
    "    print(\"✅ cust_order.csv created\")\n",
    "generate_cust_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef1209c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ order_line.csv created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_order_line():\n",
    "    record_count = 4000 + 2000 + 1000 + 300 + 500 + 50\n",
    "    order_ids = [random.randint(1000, 9999) for _ in range(record_count)]\n",
    "    book_ids = [random.randint(1, 11126) for _ in range(record_count)]\n",
    "    prices = [round(random.uniform(0, 20), 2) for _ in range(record_count)]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'order_id': order_ids,\n",
    "        'book_id': book_ids,\n",
    "        'price': prices\n",
    "    })\n",
    "    df.to_csv(f\"{output_folder}/order_line.csv\", index=False)\n",
    "    print(\"✅ order_line.csv created\")\n",
    "generate_order_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a101afb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ order_history.csv created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def generate_order_history():\n",
    "    record_count = 7547 + 6800 + 4000 + 3500 + 300 + 200\n",
    "    order_ids = list(range(1001, 1001 + record_count))\n",
    "    status_ids = [1]*7547 + [2]*6800 + [3]*4000 + [4]*3500 + [5]*300 + [6]*200\n",
    "    random.shuffle(status_ids)\n",
    "    status_dates = [datetime.now() - timedelta(days=random.randint(1, 30)) for _ in range(len(status_ids))]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'order_id': random.choices(order_ids, k=len(status_ids)),\n",
    "        'status_id': status_ids,\n",
    "        'status_date': [d.strftime('%Y-%m-%d %H:%M:%S') for d in status_dates]\n",
    "    })\n",
    "    df.to_csv(f\"{output_folder}/order_history.csv\", index=False)\n",
    "    print(\"✅ order_history.csv created\")\n",
    "generate_order_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfebb18d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 All SQL files processed and missing ones generated as CSV.\n"
     ]
    }
   ],
   "source": [
    "print('🎉 All SQL files processed and missing ones generated as CSV.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0db47f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: address.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: ADDRESS\n",
      "Shape: (999, 5)\n",
      "Missing values:\n",
      " 1                      0\n",
      "57                     0\n",
      "Glacier Hill Avenue    0\n",
      "Torbat-e Jām           0\n",
      "95                     0\n",
      "dtype: int64\n",
      "Loading: address_status.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: ADDRESS_STATUS\n",
      "Shape: (1, 2)\n",
      "Missing values:\n",
      " 1         0\n",
      "Active    0\n",
      "dtype: int64\n",
      "Loading: author.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: AUTHOR\n",
      "Shape: (9234, 2)\n",
      "Missing values:\n",
      " A. Bartlett Giamatti    0\n",
      "1                       2\n",
      "dtype: int64\n",
      "Loading: book.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: BOOK\n",
      "Shape: (36, 7)\n",
      "Missing values:\n",
      " The World''s First Love: Mary  Mother of God     0\n",
      "1                                               10\n",
      "8987059752                                      10\n",
      "2                                               10\n",
      "276                                             10\n",
      "1996-09-01                                      10\n",
      "1010                                            10\n",
      "dtype: int64\n",
      "Loading: book_author.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: BOOK_AUTHOR\n",
      "Shape: (17641, 2)\n",
      "Missing values:\n",
      " 1570    0\n",
      "2823    0\n",
      "dtype: int64\n",
      "Loading: book_language.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: BOOK_LANGUAGE\n",
      "Shape: (26, 3)\n",
      "Missing values:\n",
      " eng        0\n",
      "1          0\n",
      "English    0\n",
      "dtype: int64\n",
      "Loading: country.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: COUNTRY\n",
      "Shape: (231, 2)\n",
      "Missing values:\n",
      " 1              0\n",
      "Afghanistan    2\n",
      "dtype: int64\n",
      "Loading: cust_order.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: CUST_ORDER\n",
      "Shape: (7550, 4)\n",
      "Missing values:\n",
      " order_date            0\n",
      "customer_id           0\n",
      "shipping_method_id    0\n",
      "dest_address_id       0\n",
      "dtype: int64\n",
      "Loading: customer.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: CUSTOMER\n",
      "Shape: (1999, 4)\n",
      "Missing values:\n",
      " 1                     0\n",
      "Ursola                0\n",
      "Purdy                 0\n",
      "upurdy0@cdbaby.com    0\n",
      "dtype: int64\n",
      "Loading: customer_address.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: CUSTOMER_ADDRESS\n",
      "Shape: (3350, 3)\n",
      "Missing values:\n",
      " customer_id    0\n",
      "address_id     0\n",
      "status_id      0\n",
      "dtype: int64\n",
      "Loading: order_history.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: ORDER_HISTORY\n",
      "Shape: (22347, 3)\n",
      "Missing values:\n",
      " order_id       0\n",
      "status_id      0\n",
      "status_date    0\n",
      "dtype: int64\n",
      "Loading: order_line.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: ORDER_LINE\n",
      "Shape: (7850, 3)\n",
      "Missing values:\n",
      " order_id    0\n",
      "book_id     0\n",
      "price       0\n",
      "dtype: int64\n",
      "Loading: order_status.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: ORDER_STATUS\n",
      "Shape: (5, 2)\n",
      "Missing values:\n",
      " 1                 0\n",
      "Order Received    0\n",
      "dtype: int64\n",
      "Loading: publisher.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: PUBLISHER\n",
      "Shape: (567, 2)\n",
      "Missing values:\n",
      " 10/18     0\n",
      "1        36\n",
      "dtype: int64\n",
      "Loading: shipping_method.csv\n",
      "\n",
      "========================================\n",
      "DATAFRAME: SHIPPING_METHOD\n",
      "Shape: (3, 3)\n",
      "Missing values:\n",
      " 1           0\n",
      "Standard    0\n",
      "5.9         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load CSVs and check structure\n",
    "folder_path = '.'\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith('.csv') and not f.startswith('cleaned_')]\n",
    "\n",
    "for file in sorted(files):\n",
    "    print(f\"Loading: {file}\")\n",
    "    df = pd.read_csv(file)\n",
    "    print(f\"\\n{'='*40}\\nDATAFRAME: {file.upper().replace('.CSV','')}\\nShape: {df.shape}\")\n",
    "    print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf0c03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning: address.csv\n",
      "Cleaning: address_status.csv\n",
      "Cleaning: author.csv\n",
      "Cleaning: book.csv\n",
      "Cleaning: book_author.csv\n",
      "Cleaning: book_language.csv\n",
      "Cleaning: country.csv\n",
      "Cleaning: cust_order.csv\n",
      "Cleaning: customer.csv\n",
      "Cleaning: customer_address.csv\n",
      "Cleaning: order_history.csv\n",
      "Cleaning: order_line.csv\n",
      "Cleaning: order_status.csv\n",
      "Cleaning: publisher.csv\n",
      "Cleaning: shipping_method.csv\n",
      "✅ Cleaned files saved with 'cleaned_' prefix.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "files = [f for f in os.listdir('.') if f.endswith('.csv') and not f.startswith('cleaned_')]\n",
    "\n",
    "for file in sorted(files):\n",
    "    print(f\"Cleaning: {file}\")\n",
    "    df = pd.read_csv(file)\n",
    "    df_cleaned = df.dropna()\n",
    "    df_cleaned.to_csv(f\"cleaned_{file}\", index=False)\n",
    "\n",
    "print(\"✅ Cleaned files saved with 'cleaned_' prefix.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c9ab666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_count</th>\n",
       "      <th>shipping_variation</th>\n",
       "      <th>address_count</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  order_count  shipping_variation  address_count  churn\n",
       "0            1     0.250000            0.666667       0.250000      0\n",
       "1            2     0.416667            0.666667       0.416667      0\n",
       "2            4     0.166667            0.333333       0.166667      1\n",
       "3            5     0.166667            0.333333       0.166667      1\n",
       "4            6     0.666667            0.666667       0.666667      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "cust_order = pd.read_csv(\"cleaned_cust_order.csv\")\n",
    "cust_order[\"order_date\"] = pd.to_datetime(cust_order[\"order_date\"])\n",
    "\n",
    "# Create churn labels\n",
    "cutoff = cust_order[\"order_date\"].max() - timedelta(days=180)\n",
    "last_order = cust_order.groupby(\"customer_id\")[\"order_date\"].max().reset_index()\n",
    "last_order[\"churn\"] = (last_order[\"order_date\"] < cutoff).astype(int)\n",
    "\n",
    "# Aggregate features\n",
    "features = cust_order.groupby(\"customer_id\").agg({\n",
    "    \"order_date\": \"count\",\n",
    "    \"shipping_method_id\": \"nunique\",\n",
    "    \"dest_address_id\": \"nunique\"\n",
    "}).reset_index()\n",
    "features.columns = [\"customer_id\", \"order_count\", \"shipping_variation\", \"address_count\"]\n",
    "\n",
    "# Merge and normalize\n",
    "df = pd.merge(features, last_order[[\"customer_id\", \"churn\"]], on=\"customer_id\")\n",
    "for col in [\"order_count\", \"shipping_variation\", \"address_count\"]:\n",
    "    df[col] = (df[col] - df[col].min()) / (df[col].max() - df[col].min() + 1e-9)\n",
    "\n",
    "df.to_csv(\"churn_model_data.csv\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ab5a976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression Accuracy: 0.6497\n",
      "RandomForest Accuracy: 0.6497\n",
      "DecisionTree Accuracy: 0.6514\n",
      "KNN Accuracy: 0.6054\n",
      "✅ Best Model: DecisionTree with accuracy 0.6514\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"churn_model_data.csv\")\n",
    "X = df[[\"order_count\", \"shipping_variation\", \"address_count\"]]\n",
    "y = df[\"churn\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "# Train and evaluate\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, preds)\n",
    "    print(f\"{name} Accuracy: {score:.4f}\")\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_model = model\n",
    "        best_model_name = name\n",
    "\n",
    "# Save the best model\n",
    "with open(\"best_churn_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(best_model, f)\n",
    "\n",
    "print(f\"✅ Best Model: {best_model_name} with accuracy {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fba49264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_count</th>\n",
       "      <th>shipping_variation</th>\n",
       "      <th>address_count</th>\n",
       "      <th>churn</th>\n",
       "      <th>predicted_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  order_count  shipping_variation  address_count  churn  \\\n",
       "0            1     0.250000            0.666667       0.250000      0   \n",
       "1            2     0.416667            0.666667       0.416667      0   \n",
       "2            4     0.166667            0.333333       0.166667      1   \n",
       "3            5     0.166667            0.333333       0.166667      1   \n",
       "4            6     0.666667            0.666667       0.666667      0   \n",
       "5            7     0.083333            0.333333       0.083333      0   \n",
       "6            8     0.333333            0.333333       0.333333      1   \n",
       "7            9     0.500000            0.666667       0.500000      1   \n",
       "8           10     0.250000            0.666667       0.250000      0   \n",
       "9           11     0.666667            1.000000       0.666667      0   \n",
       "\n",
       "   predicted_churn  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                1  \n",
       "4                0  \n",
       "5                1  \n",
       "6                0  \n",
       "7                0  \n",
       "8                0  \n",
       "9                0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pickle\n",
    "model = pickle.load(open(\"best_churn_model.pkl\", \"rb\"))\n",
    "df[\"predicted_churn\"] = model.predict(X)\n",
    "df.to_csv(\"churn_prediction_results.csv\", index=False)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd50fc18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>order_count</th>\n",
       "      <th>shipping_variation</th>\n",
       "      <th>address_count</th>\n",
       "      <th>churn</th>\n",
       "      <th>predicted_churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  order_count  shipping_variation  address_count  churn  \\\n",
       "0            1     0.250000            0.666667       0.250000      0   \n",
       "1            2     0.416667            0.666667       0.416667      0   \n",
       "2            4     0.166667            0.333333       0.166667      1   \n",
       "3            5     0.166667            0.333333       0.166667      1   \n",
       "4            6     0.666667            0.666667       0.666667      0   \n",
       "\n",
       "   predicted_churn  \n",
       "0                0  \n",
       "1                0  \n",
       "2                1  \n",
       "3                1  \n",
       "4                0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"churn_prediction_results.csv\")\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
